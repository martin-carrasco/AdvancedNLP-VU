{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fda4edc-7f6a-464b-b17a-415435d4dcdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def adding_headers_and_add_IDs_to_sentences(input_filepath, output_filepath):\n",
    "    sentence_id = 1  # Initialize sentence ID counter\n",
    "\n",
    "    # Open input file for reading and output file for writing    \n",
    "    with open(input_filepath, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_filepath, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            line = line.strip()  # Remove leading/trailing whitespaces\n",
    "\n",
    "            # Skip lines that are either empty or start with '#'\n",
    "            if line and not line.startswith('#'):\n",
    "                # Write the line along with the sentence ID to the output file\n",
    "                outfile.write(f'{sentence_id}\\t{line}\\n')\n",
    "            else:\n",
    "                # If the line is empty, it marks the end of a sentence\n",
    "                if not line:\n",
    "                    sentence_id += 1  # Increment sentence ID for the next sentence\n",
    "\n",
    "                    \n",
    "    # Open the processed output file for reading         \n",
    "    with open(output_filepath, encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Split each line into columns based on the tab character\n",
    "    data = [line.strip().split('\\t') for line in lines]\n",
    "    \n",
    "    # Find the maximum number of columns in any row\n",
    "    max_columns = max(len(row) for row in data)\n",
    "    print(max_columns)\n",
    "    \n",
    "    # Create a DataFrame with column names 'col_0', 'col_1', ..., 'col_(max_columns-1)'    \n",
    "    new_df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(max_columns)])\n",
    "\n",
    "# --- code above not changed ---\n",
    "\n",
    "    \n",
    "    # Rename only the first 11 columns (sentence_num + 10 other - see assignment guidelines)\n",
    "    additional_cols = [f'col_{i}' for i in range(12, max_columns)]    ### 11 changed to 12\n",
    "    new_df.columns = ['sentence_id', 'token_id', 'token', 'lemma', 'UPOS', 'POS', 'grammar', 'head_id', 'dependency_relation',\n",
    "                      'head_dependency_relation', 'additional_info', 'PropBank_frames'] + additional_cols   ### 'token_id' added, 'is_predicate' changed to 'PropBank_frames', 'sentence_num' changed to 'sentence_id' \n",
    "    \n",
    "    return new_df        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Perform the preprocessing and save the result to a CSV file\n",
    "    df = adding_headers_and_add_IDs_to_sentences('../Data/en_ewt-up-train.conllu', '../Data/en_ewt-up-train_new.conllu')\n",
    "    # df.to_csv('../Data/train(Nur).tsv', index=False)\n",
    "    df.to_csv('../Data/train_header_added.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0504d148-f9b6-46ab-915b-fc2c47aa0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data/train_header_added.tsv'\n",
    "output_path = '../Data/duplicated_train.tsv'\n",
    "\n",
    "\n",
    "with open(input_path, \"r\", encoding = \"utf-8\") as inputfile:\n",
    "    for line in inputfile:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        \n",
    "        # condition1: sentences with 1 predicate\n",
    "        if len(columns) == 13:\n",
    "            new_line = \"\\t\".join(columns)+\"\\n\"\n",
    "            with open(output_path, \"a\", encoding=\"utf-8\") as output:\n",
    "                output.write(new_line)\n",
    "                \n",
    "                \n",
    "        # condition2: sentences with more than 1 predicates\n",
    "        else:\n",
    "            for i in range(14, 48):\n",
    "                if len(columns) == i:\n",
    "                    # combine first 12 columns with different V&Arug column\n",
    "                    new_line = \"\\t\".join(columns[0:12] + [columns[i-1]]) + \"\\n\"\n",
    "                    with open(output_path, \"a\", encoding=\"utf-8\") as output:\n",
    "                        output.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79eed117-0ad5-474b-b819-5a733072702d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "for i in range(14, 48):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f008c9f-ca8e-4d52-976b-106ea4b51cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00ef62-52b0-4fbf-b196-04dbde092914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c08fb-5084-4064-b493-bd442630aee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
